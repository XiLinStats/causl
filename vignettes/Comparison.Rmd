---
title: "Comparison of Methods"
author: "Robin J. Evans"
date: "25/05/2021"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Comparison of Methods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  echo = TRUE,
  comment = "#>",
  cache = TRUE,
  fig.width=7, 
  fig.height=7
)
# knitr::knit_theme$set("earendel")
```

As always, we begin by loading the package.
```{r load, include=TRUE, message=FALSE}
library(causl)
library(purrr)
library(survey)
```

## Simulate Data

We first select the variables in our model, choosing the ones mentioned 
in the running example of Evans and Didelez (2021).  In this case the model is
given by the graph $A_0 \rightarrow L \rightarrow A_1 \rightarrow Y$ with
$A_0 \rightarrow A_1$ and $L \leftrightarrow Y$.
```{r formulas}
forms <- list(L ~ A0, 
              list(A0 ~ 1, A1 ~ A0*L),
              Y ~ A0*A1, 
              ~ A0)
```

We next select the parameters for our model, again following 
Evans and Didelez (2021).

```{r params}
pars <- list(A0 = list(beta = 0),
             L = list(beta = c(0.3,-0.2), phi=1),
             A1 = list(beta = c(-0.3,0.4,0.3,0)), 
             Y = list(beta = c(-0.5,0.2,0.3,0), phi=1),
             cop = list(beta = c(1,0.5)))
```

Now we sample $10^6$ observations from the model:
```{r simulate}
set.seed(124)
# dat_max <- causalSamp(1e6, formulas = forms, pars=pars, family = list(3,c(5,5),1,1))
dat_max <- causalSamp(1e3, formulas = forms, pars=pars, family = list(3,c(5,5),1,1))
```
Then we can check that the distribution actually has the correct form for the
first three variables ($A_0, L, A_1$):
```{r glms1, echo=-1}
options(digits=3)
summary(glm(A0 ~ 1, family=binomial, data=dat_max))$coef
summary(glm(L ~ A0, family=Gamma(link="log"), data=dat_max))$coef
glmA1 <- glm(A1 ~ A0*L, family=binomial, data=dat_max)
summary(glmA1)$coef
```
Indeed, all the parameters are close to their correct values.

We can also use inverse probability weighting to check the causal relationship 
for $Y$.
```{r chk}
ps <- fitted(glmA1)
wt <- dat_max$A1/ps + (1-dat_max$A1)/(1-ps)
summary(lm(Y ~ A0*A1, data=dat_max, weights = wt))$coef
```

<!-- summary(glm(L ~ A0, family=Gamma(link="log"), data=dat))$coef -->
<!-- glmA1 <- glm(A1 ~ A0*L, family=binomial, data=dat) -->
<!-- summary(glmA1)$coef -->
<!-- wts <- predict(glmA1, type="response") -->
<!-- wts[dat$A1 == 0] <- 1 - wts[dat$A1 == 0] -->
<!-- summary(glm(Y ~ A0*A1, weight=1/wts, data=dat)) -->

For the remainder of this vignette, we will only use the first 10,000 entries 
of this dataset.  
```{r dat}
# dat <- dat_max[seq_len(1e4), ]
dat <- dat_max[seq_len(1e2), ]
```


### Outcome Regression

We start with a na\"{i}ve outcome regression approach, where we fit a linear 
model for $Y$ regressed on various combinations of $A_0,A_1$ and $L$.  As we can
see, none yield the parameters that interest us.

```{r outcome}
lmY_A0A1 <- lm(Y ~ A0*A1, data=dat)
lmY_A0A1_L <- lm(Y ~ A0*A1 + L, data=dat)
lmY_A0A1L <- lm(Y ~ A0*A1*L, data=dat)
summary(lmY_A0A1)$coef
summary(lmY_A0A1_L)$coef
summary(lmY_A0A1L)$coef
```

```{r tab_or, echo=FALSE}
tab_or <- summary(lmY_A0A1)$coef[,1:2]
tab_or <- cbind(tab_or, tab_or[,1] - pars$Y$beta)
colnames(tab_or) <- c("Est.", "SE", "Bias")
```

### Inverse Propensity Weighting

We can try the rather more principled approach of using 
inverse propensity score weighting, and this time the estimates are unbiased. 

```{r ipw}
## get the weights from model for A1
glmA1 <- glm(A1 ~ A0*L, family=binomial, data=dat)
ps <- fitted(glmA1)
wt <- dat$A1/ps + (1-dat$A1)/(1-ps) 

lmY_A0A1_w <- lm(Y ~ A0*A1, data=dat, weights = wt)
summary(lmY_A0A1_w)$coef
```
Notice that the coefficients are now correct.
```{r tab_ipw, echo=FALSE}
tab_ipw <- summary(lm(Y ~ A0*A1, data=dat, weights = wt))$coef[,1:2]
tab_ipw <- cbind(tab_ipw, tab_ipw[,1] - pars$Y$beta)
colnames(tab_ipw) <- c("Est.", "SE", "Bias")
```

### Doubly Robust Approach

We can also use an approach based on doubly-robust estimating equations.

```{r, echo=FALSE, eval=TRUE}
glmY <- lm(Y ~ A0*A1*I(log(L)), data=dat)
glmA0 <- glm(A0 ~ 1, data=dat, family=binomial)
dat0 <- dat1 <- dat00 <- dat10 <- dat01 <- dat11 <- dat
dat0$A1 = 0
dat1$A1 = 1
dat00[,c("A0", "A1")] = 0
dat10[,c("A0", "A1")] = rep(c(1,0), each=nrow(dat))
dat01[,c("A0", "A1")] = rep(c(0,1), each=nrow(dat))
dat11[,c("A0", "A1")] = 1

## weights
w1 <- fitted(glmA1)
w1[dat$A1==0] <- 1 - w1[dat$A1==0]
w0 <- rep(1, nrow(dat))
# w0 <- predict(glmA0, dat, "response")
# w0[dat$A0==0] <- 1 - w0[dat$A0==0]
w <- w0 * w1

q <- predict(glmY, dat)
q0 <- predict(glmY, dat0)
q1 <- predict(glmY, dat1)
q00 <- predict(glmY, dat00)
q01 <- predict(glmY, dat01)
q10 <- predict(glmY, dat10)
q11 <- predict(glmY, dat11)

## predict outcomes
wts1 <- (dat$Y - q)*dat$A1/w + q1
# mean(wts1)
# sd(wts1)/sqrt(nrow(dat))

wts0 <- (dat$Y - q)*(1-dat$A1)/w + q0
# mean(wts0)
# sd(wts0)/sqrt(nrow(dat))

mean(wts1 - wts0)
# sd(wts1 - wts0)/sqrt(nrow(dat))

wts11 <- (dat$Y - q)*dat$A1*dat$A0/w + q11
wts10 <- (dat$Y - q)*(1-dat$A1)*dat$A0/w + q10
wts01 <- (dat$Y - q)*dat$A1*(1-dat$A0)/w + q01
wts00 <- (dat$Y - q)*(1-dat$A1)*(1-dat$A0)/w + q00

tab_dr <- cbind(c(mean(wts00), mean(wts10 - wts00), mean(wts01 - wts00), mean(wts11 - wts01 - wts10 + wts00)), 
                c(sd(wts00),
                  sd(wts10 - wts00), 
                  sd(wts01 - wts00), 
                  sd(wts11 - wts01 - wts10 + wts00))/sqrt(nrow(dat)))
tab_dr <- cbind(tab_dr, tab_dr[,1] - pars$Y$beta)
colnames(tab_dr) <- c("Est.", "SE", "Bias")
```
```{r dr, eval=TRUE}
## get datasets with different values of A1
dat0 <- dat1 <- dat
dat0$A1 <- 0
dat1$A1 <- 1

## get outcome models
glmY <- lm(Y ~ A1*I(log(L)), data=dat)
q <- predict(glmY, dat)
q0 <- predict(glmY, dat0)
q1 <- predict(glmY, dat1)

n0 <- sum(dat$A0 == 0)
n1 <- sum(dat$A0 == 1)

## obtain E[Y | do(A0=a0,A1=a1)] for each (a0,a1)
wts01 <- ((dat$Y - q)*dat$A1/w + q1)[dat$A0 == 0]
wts00 <- ((dat$Y - q)*(1-dat$A1)/w + q0)[dat$A0 == 0]
wts11 <- ((dat$Y - q)*dat$A1/w + q1)[dat$A0 == 1]
wts10 <- ((dat$Y - q)*(1-dat$A1)/w + q0)[dat$A0 == 1]
se00 <- sd(wts00)/sqrt(n0)
se10 <- sd(wts10)/sqrt(n1)
se01 <- sd(wts01)/sqrt(n0)
se11 <- sd(wts11)/sqrt(n1)

cse00_01 <- mean((wts00 - mean(wts00))*(wts01 - mean(wts01)))/n0
cse10_11 <- mean((wts10 - mean(wts10))*(wts11 - mean(wts11)))/n1

## use these to obtain estimates, standard errors and bias
est <- c(mean(wts00), mean(wts10) - mean(wts00), mean(wts01 - wts00), mean(wts11 - wts10) - mean(wts01 - wts00))
se <- c(se00, 
        sqrt(se10^2 - 2*cse00_01 + se00^2), 
        sqrt(se01^2 + se00^2),
        sqrt(se10^2 - 2*cse00_01 + se00^2) + sqrt(se10^2 - 2*cse10_11 + se11^2))
tab_dr <- cbind(est, se)
rownames(tab_dr) <- rownames(tab_ipw)
tab_dr
```

```{r tab_dr}
bias <- est - pars$Y$beta
tab_dr <- cbind(est, se, bias)
colnames(tab_dr) <- c("Est.", "SE", "Bias")
```

### Maximum Likelihood

Finally, we can fit using our own code with the black-box 
optimizer, and since we are fitting the correct model it is
guaranteed to be consistent and asymptotically efficient.


```{r mle, cache=TRUE}
modY <- fitCausal(dat, formulas = list(Y ~ A0*A1, L ~ A0, ~ A0*A1),
                  family = c(1,3,1), control=list(maxit=2e4, newton=TRUE))
modY
```

```{r tab_mle, echo=FALSE, cache=TRUE}
tab_mle <- cbind(modY$pars$Y$beta[1:4], modY$pars$Y$beta_se[1:4], 
                 modY$pars$Y$beta[1:4]-pars$Y$beta)
colnames(tab_mle) <- c("Est.", "SE", "Bias")
```


### Comparison of Results

Outcome regression fails miserably, but this is to be expected because the model
is hopelessly misspecified.  IP weighting, double robust estimates and the MLE
all appear to be correct.  

```{r results, echo=FALSE, results="asis"}
results <- cbind(tab_or, tab_ipw, tab_dr, tab_mle)
results[,1+rep(0:3, each=1)*3] <- round(results[,1+rep(0:3, each=1)*3], 2)
results[,2+rep(0:3, each=1)*3] <- round(results[,2+rep(0:3, each=1)*3], 3)
results[,3+(0:3)*3] <- round(results[,3+(0:3)*3], 3)
results[,ncol(results)] <- round(results[,ncol(results)], 3)
kableExtra::kbl(results, booktabs=TRUE) %>%
  kableExtra::add_header_above(c(" ","Outcome Regression"=3,"IP Weighting"=3,"Double Robust"=3,"MLE"=3))
# xtable::xtable(results, digits=c(0,rep(c(2,3,3),4)), align="|r|rrr|rrr|rrr|")
```

